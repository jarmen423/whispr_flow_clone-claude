# LocalFlow

<div align="center">

**A hybrid cloud/local dictation system with real-time processing**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.7-blue)](https://www.typescriptlang.org/)
[![Next.js](https://img.shields.io/badge/Next.js-15-black)](https://nextjs.org/)

[Features](#features) â€¢ [Quick Start](#quick-start) â€¢ [Documentation](#documentation) â€¢ [Contributing](#contributing)

</div>

---

## âœ¨ Features

- **ğŸ¤ Real-time Dictation** - Record and transcribe audio instantly with beautiful web interface
- **â˜ï¸ Dual Processing** - Cloud (z-ai SDK) or Local (Whisper.cpp + Ollama) modes
- **ğŸ–¥ï¸ Desktop Agent** - System-wide dictation with global hotkey support (Alt+V)
- **ğŸ¯ Intelligent Refinement** - 4 modes: Developer, Concise, Professional, Raw
- **ğŸŒ Modern Web UI** - Responsive interface with real-time WebSocket communication
- **ğŸ“‹ History** - Persistent dictation history with one-click copy
- **âš¡ Fast** - <3s cloud latency, <5s local latency
- **ğŸ”’ Privacy** - Optional local-only processing with complete data privacy

## ğŸš€ Quick Start

### Prerequisites

- [Bun](https://bun.sh/) or Node.js 18+
- ZAI API key (for cloud mode)
- Python 3.8+ (for desktop agent, optional)

### Installation

```bash
# Clone repository
git clone <repository-url>
cd localflow

# Install dependencies
bun install
```

### Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your ZAI_API_KEY
nano .env
```

### Run Development Server

```bash
# Option 1: Run all services together
bun run dev:all

# Option 2: Run services separately
bun run websocket:dev  # Terminal 1
bun run dev            # Terminal 2
```

### Open Web Interface

Visit [http://localhost:3000](http://localhost:3000) in your browser.

### (Optional) Desktop Agent

```bash
cd agent
pip install -r requirements.txt
python localflow-agent.py
```

Press `Alt+V` to start/stop recording from anywhere!

## ğŸ“– Documentation

- **[User Guide](LOCALFLOW_README.md)** - Complete usage instructions
- **[Local Mode Setup](SETUP_LOCAL.md)** - Offline processing with Whisper.cpp and Ollama
- **[Agent Guide](agent/README.md)** - Desktop agent documentation
- **[Changelog](CHANGELOG.md)** - Version history and changes

## ğŸ¯ Processing Modes

### Cloud Mode (z-ai SDK)

âœ… Higher accuracy
âœ… Faster processing
âœ… No local setup

âŒ Requires internet
âŒ API costs may apply
âŒ Privacy concerns

### Local Mode (Whisper.cpp + Ollama)

âœ… Complete privacy
âœ… No internet required
âœ… No API costs
âœ… Works offline

âŒ Slower processing
âŒ Requires powerful hardware
âŒ More complex setup

See [SETUP_LOCAL.md](SETUP_LOCAL.md) for local mode setup.

## ğŸ¨ Refinement Modes

- **Developer** - Fixes technical terms (`git commit`, `npm install`, `GitHub`)
- **Concise** - Removes filler words and shortens text
- **Professional** - Formal business language
- **Raw** - Returns unchanged transcription

## ğŸ—ï¸ Project Structure

```
localflow/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                 # Next.js app router
â”‚   â”‚   â”œâ”€â”€ api/            # API routes
â”‚   â”‚   â”‚   â””â”€â”€ dictation/  # Transcribe & refine endpoints
â”‚   â”‚   â”œâ”€â”€ page.tsx        # Main web UI
â”‚   â”‚   â””â”€â”€ layout.tsx      # Root layout
â”‚   â”œâ”€â”€ components/ui/      # shadcn/ui components
â”‚   â”œâ”€â”€ hooks/              # React hooks (WebSocket, toast, mobile)
â”‚   â””â”€â”€ lib/                # Utilities and types
â”‚       â”œâ”€â”€ transcribe/     # Cloud & local transcription
â”‚       â”œâ”€â”€ refine/         # Cloud & local refinement
â”‚       â”œâ”€â”€ types.ts        # TypeScript definitions
â”‚       â””â”€â”€ prompts.ts      # Refinement system prompts
â”œâ”€â”€ mini-services/
â”‚   â””â”€â”€ websocket-service/  # Socket.IO server
â”œâ”€â”€ agent/                  # Python desktop agent
â”‚   â”œâ”€â”€ localflow-agent.py
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ public/                 # Static assets
```

## ğŸ› ï¸ Development

### Scripts

```bash
bun run dev          # Start Next.js dev server
bun run build        # Build for production
bun run start        # Start production server
bun run lint         # Run ESLint
bun run test         # Run tests
```

### WebSocket Service

```bash
bun run websocket:dev        # Development mode
WS_PORT=3010 bun run mini-services/websocket-service/index.ts  # Custom port
```

### Desktop Agent

```bash
cd agent
pip install -r requirements.txt
python localflow-agent.py
```

## ğŸ§ª Testing

```bash
# Run integration test
bun run test

# Manual testing checklist
- [ ] WebSocket service starts on port 3001
- [ ] Web UI loads at localhost:3000
- [ ] Agent connections work
- [ ] Cloud transcription works
- [ ] Local transcription works (if configured)
- [ ] All refinement modes work
- [ ] Desktop agent hotkey works
- [ ] Text pastes correctly
```

## ğŸ“Š Performance

| Mode | Latency | Accuracy | Privacy | Cost |
|------|---------|----------|---------|------|
| Cloud | <3s | 99%+ | âŒ | ğŸ’° |
| Local | <5s | 95%+ | âœ… | Free |

*Benchmarks on M1 MacBook Pro with 10s audio sample*

## ğŸ”’ Privacy

### Cloud Mode
- Audio sent to z-ai servers for processing
- Check z-ai's privacy policy for data handling
- No permanent storage by LocalFlow

### Local Mode
- All processing happens on your machine
- No data leaves your computer
- Complete privacy and offline capability

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ› Troubleshooting

### Common Issues

**WebSocket service won't start**
```bash
# Kill process on port 3001
lsof -ti:3001 | xargs kill -9
```

**Desktop agent hotkey doesn't work**
- Linux: Run with `sudo` or add user to `input` group
- macOS: Grant accessibility permissions
- Windows: Run as Administrator

**Transcription fails**
- Cloud: Check ZAI_API_KEY and internet connection
- Local: Verify Whisper.cpp and Ollama are running

See [LOCALFLOW_README.md](LOCALFLOW_README.md) for more troubleshooting tips.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [z-ai SDK](https://z-ai.dev) - Cloud transcription and refinement
- [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) - Local speech recognition
- [Ollama](https://ollama.com) - Local LLM inference
- [Socket.IO](https://socket.io) - Real-time communication
- [Next.js](https://nextjs.org) - React framework
- [shadcn/ui](https://ui.shadcn.com) - UI components
- [Framer Motion](https://www.framer.com/motion/) - Animation library

## ğŸ“® Support

- ğŸ“§ Email: support@localflow.dev
- ğŸ› Issues: [GitHub Issues](https://github.com/your-repo/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/your-repo/discussions)
- ğŸ“– Docs: [Full Documentation](https://docs.localflow.dev)

---

<div align="center">

**Built with â¤ï¸ by the LocalFlow team**

[â­ Star us on GitHub](https://github.com/your-repo) â€¢ [ğŸ¦ Follow us on Twitter](https://twitter.com/localflow)

</div>
